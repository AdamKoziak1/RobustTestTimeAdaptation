

TRAIN: python train.py --output train_output --dataset PACS --data_file /home/adam/Downloads/RobustTestTimeAdaptation

**** CUDA_VISIBLE_DEVICES=1 python train.py --output train_output --dataset DomainNet --test_envs 4 --batch_size 64



ADAPT: python unsupervise_adapt.py --dataset PACS --data_dir /home/adam/Downloads/RobustTestTimeAdaptation/datasets/PACS --adapt_alg TENT --batch_size 1 --attack_rate 50 --mask_id 0
./run_domain.sh 

resnet18 first, then resnet50. insufficient VRAM for VIT (at default batch size at least)


TODO:
implement lambda1 loss
implement lambda2 loss
  make L_0 (stop gradient) a hyperparameter


finish train on officehome 3
 (hold off on domainnet 4,5)
run data_generation on officenet

CUDA_VISIBLE_DEVICES=1 python generate_adv_data.py --dataset PACS
python adv/generate_masks.py --dataset PACS
CUDA_VISIBLE_DEVICES=1 python generate_adv_data.py --dataset office-home
python adv/generate_masks.py --dataset office-home
CUDA_VISIBLE_DEVICES=1 python generate_adv_data.py --dataset VLCS
python adv/generate_masks.py --dataset VLCS


  0 0 0
  0 1 0

cuda0

cuda1

cuda2

cuda3



  1 1 1 'cosine'
  1 1 1 'l2'
  1 0 0
  0 0 1 'l2'
  0 0 1 'cosine'
  0 1 1 'cosine'

  0 1 1 'l2'
  1 1 0
  1 0 1 'cosine'
  1 0 1 'l2'






unsupervise_adapt on all dataset/mask/alg combs (compare against 5+ methods, ideally SOTA)

add stddev in results

look at t3a, why is it robust

ablation on loss terms