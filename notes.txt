

TRAIN: python train.py --output train_output --dataset PACS --data_file /home/adam/Downloads/RobustTestTimeAdaptation

**** CUDA_VISIBLE_DEVICES=1 python train.py --output train_output --dataset DomainNet --test_envs 4 --batch_size 64



ADAPT: python unsupervise_adapt.py --dataset PACS --data_dir /home/adam/Downloads/RobustTestTimeAdaptation/datasets/PACS --adapt_alg TENT --batch_size 1 --attack_rate 50 --mask_id 0
./run_domain.sh 

resnet18 first, then resnet50. insufficient VRAM for VIT (at default batch size at least)


TODO:
implement lambda1 loss
implement lambda2 loss
  make L_0 (stop gradient) a hyperparameter


finish train on officehome 3
 (hold off on domainnet 4,5)
run data_generation on officenet

CUDA_VISIBLE_DEVICES=1 python generate_adv_data.py --dataset PACS
python adv/generate_masks.py --dataset PACS
CUDA_VISIBLE_DEVICES=1 python generate_adv_data.py --dataset office-home
python adv/generate_masks.py --dataset office-home
CUDA_VISIBLE_DEVICES=1 python generate_adv_data.py --dataset VLCS
python adv/generate_masks.py --dataset VLCS




hyperparam sweep on each lambda and cr type. maybe get unified accuracy over domains/datasets as signal to optimize


online vs offline (toggle episodic)
  sweep both
  adapt on both
  


unsupervise_adapt on all dataset/mask/alg combs (compare against 5+ methods, ideally SOTA)
  *online specifically, make sure setting is consistent
  define online, are we doing it? do we want to?
    episodic set to true for sweep, attack rate 100, average over all domains and datasets.


add stddev in results

ablation on loss terms